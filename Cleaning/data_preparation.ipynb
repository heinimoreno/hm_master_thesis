{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Merging Players Data for Playing Minutes Overview \n",
    "## General Information  \n",
    "**Objective**  \n",
    "This script cleans and merges scraped data located in the data/raw folder to allow in-depth analysis of player statistics.\n",
    "\n",
    "**Scope**\n",
    "This script processes and cleans the following datasets:\n",
    "\n",
    "- players_current.csv → cleaned to players_cleaned.csv\n",
    "- lineups.csv → cleaned and saved as lineups_prep.csv\n",
    "- lineups_prep.csv and match_events.csv → merged and saved as lineups_cleaned.csv\n",
    "- Using lineups_prep.csv to calculate playing minutes for each player → saved as player_stats_cleaned.csv\n",
    "\n",
    "**Methodology**  \n",
    "\n",
    "- Clean datasets for proper format and calculations.\n",
    "- Merge lineup and match events data.\n",
    "- Calculate individual player statistics.\n",
    "\n",
    "**Usage**  \n",
    "Cleaned datasets will be saved to the data folder for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python Libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning Players Data  \n",
    "**Description**  \n",
    "This section cleans the players_current.csv file by:\n",
    "\n",
    "- Converting market value formats.\n",
    "- Parsing birthdates into a standardized format.\n",
    "- Calculating player ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert the market values\n",
    "def clean_market_value(value_str):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes market value strings.\n",
    "    Converts \"Mio.\" to millions and \"Tsd.\" to thousands.\n",
    "    \"\"\"\n",
    "    value_str = (\n",
    "        value_str.replace('€', '')  # Remove the euro symbol\n",
    "        .replace('â‚¬', '')  # Remove any encoding artifacts\n",
    "        .replace('Tsd.', 'k')  # Replace \"Tsd.\" with \"k\" for consistency\n",
    "        .replace('Mio.', 'm')  # Replace \"Mio.\" with \"m\" for consistency\n",
    "        .replace(',', '.')  # Replace commas with dots for float conversion\n",
    "        .strip()  # Remove leading and trailing spaces\n",
    "    )\n",
    "    market_value = 0.0\n",
    "    if 'm' in value_str:\n",
    "        # Convert values in millions\n",
    "        market_value = float(value_str.replace('m', ''))\n",
    "    elif 'k' in value_str:\n",
    "        # Convert values in thousands (divided by 1000 to get millions)\n",
    "        market_value = float(value_str.replace('k', '')) / 1000\n",
    "    return market_value\n",
    "\n",
    "# Function to extract birthdate from the Birthdate column\n",
    "def extract_birthdate(birthdate_str):\n",
    "    \"\"\"\n",
    "    Extracts the birthdate part from a string formatted as 'Date (Age)'.\n",
    "    \"\"\"\n",
    "    birthdate_part, _ = birthdate_str.split('(')  # Split the string at '(' and keep the date part\n",
    "    return birthdate_part.strip()\n",
    "\n",
    "# Function to parse date with error handling\n",
    "def parse_date(date_str, format='%d.%m.%Y'):\n",
    "    \"\"\"\n",
    "    Converts a date string into a datetime object.\n",
    "    Returns NaT if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=format, errors='coerce')  # Handle errors gracefully\n",
    "    except ValueError:\n",
    "        return pd.NaT  # Return NaT for invalid dates\n",
    "\n",
    "# Calculate age based on birthdate\n",
    "def calculate_age(birthdate):\n",
    "    \"\"\"\n",
    "    Calculates the age of a player based on their birthdate.\n",
    "    \"\"\"\n",
    "    if pd.notnull(birthdate):\n",
    "        today = datetime.today()\n",
    "        # Calculate age, adjusting for whether the birthdate has occurred this year\n",
    "        age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "        return age\n",
    "    return None\n",
    "\n",
    "# Path to the raw data file\n",
    "file_path = '../data/raw/players_NT_2024-11-12.csv'  # Replace with the actual file path\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the function to clean and convert market values\n",
    "df['Value'] = df['Value'].apply(clean_market_value)\n",
    "\n",
    "# Extract and parse the birthdate\n",
    "df['Birthdate'] = (\n",
    "    df['Birthdate']\n",
    "    .apply(extract_birthdate)  # Extract the birthdate\n",
    "    .apply(lambda x: parse_date(x, format='%d.%m.%Y'))  # Convert the string to a datetime object\n",
    ")\n",
    "\n",
    "# Calculate age based on the birthdate\n",
    "df['Age'] = df['Birthdate'].apply(calculate_age)\n",
    "\n",
    "# Remove any unnecessary spaces in the 'Name' column\n",
    "df['Name'] = df['Name'].str.strip()\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('../data/cleaned/players_cleaned.csv', index=False)  # Replace with preferred name\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Unique Players Dataset  \n",
    "\n",
    "Generates a unique dataset of players with clean birthdate formats and calculated ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned players data file\n",
    "file_path = '../data/cleaned/players_cleaned.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Keep only 'Name' and 'Birthdate' columns for further processing\n",
    "df = df[['Name', 'Birthdate']]\n",
    "\n",
    "# Remove any unnecessary spaces from the 'Name' column\n",
    "df['Name'] = df['Name'].str.strip()\n",
    "\n",
    "# Function to parse date with the correct format '%Y-%m-%d'\n",
    "def parse_date_correct(date_str):\n",
    "    \"\"\"\n",
    "    Parses date strings into datetime objects using the specified format.\n",
    "    Returns NaT for invalid or missing values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the date using the expected format\n",
    "        parsed_date = pd.to_datetime(date_str, format='%Y-%m-%d', errors='coerce')\n",
    "        return parsed_date\n",
    "    except ValueError:\n",
    "        # Return NaT if parsing fails\n",
    "        return pd.NaT\n",
    "\n",
    "# Apply the corrected date parsing function to the 'Birthdate' column\n",
    "df['Birthdate'] = df['Birthdate'].apply(parse_date_correct)\n",
    "\n",
    "# Function to calculate age based on birthdate\n",
    "def calculate_age(birthdate):\n",
    "    \"\"\"\n",
    "    Calculates the age of a player based on their birthdate.\n",
    "    \"\"\"\n",
    "    if pd.notnull(birthdate):\n",
    "        today = datetime.today()\n",
    "        # Compute age, accounting for whether the birthdate has occurred this year\n",
    "        age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "        return age\n",
    "    return None\n",
    "\n",
    "# Calculate the current age and add it as a new column 'Age'\n",
    "df['Age'] = df['Birthdate'].apply(calculate_age)\n",
    "\n",
    "# Drop duplicate rows based on 'Name' and 'Birthdate'\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Save the cleaned and processed data to a new CSV file\n",
    "output_file_path = '../data/cleaned/players_unique.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"File saved successfully at:\", output_file_path)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame for verification\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging National Team Stats  \n",
    " \n",
    "This section merges player national team statistics with cleaned player data to provide additional insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the cleaned detailed stats file and the national team stats file\n",
    "file1_path = '../data/raw/players_detailed_stats_NT.csv'  # Adjust path if necessary\n",
    "file2_path = '../data/raw/players_NT_stats_incl_ID.csv'   # Adjust path if necessary\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the two DataFrames on \"Player ID\" and \"National Team ID\"\n",
    "merged_df = pd.merge(\n",
    "    df1,\n",
    "    df2[['Player ID', 'National Team', 'Debut Date', 'National Team ID']],  # Include only relevant columns\n",
    "    on=['Player ID', 'National Team ID'],  # Merge on these common columns\n",
    "    how='left'  # Keep all rows from df1 and add matching rows from df2\n",
    ")\n",
    "\n",
    "# Rename \"National Team\" column to \"Club\" to standardize terminology\n",
    "merged_df = merged_df.rename(columns={'National Team': 'Club'})\n",
    "\n",
    "# Convert \"Debut Date\" column to a datetime object with the expected day-month-year format\n",
    "merged_df['Debut Date'] = pd.to_datetime(\n",
    "    merged_df['Debut Date'], format='%d.%m.%Y', errors='coerce'\n",
    ")\n",
    "\n",
    "# Determine \"Season Start\" and \"Season End\" based on the \"Debut Date\" month\n",
    "merged_df['Season Start'] = merged_df['Debut Date'].apply(\n",
    "    lambda x: x.year if pd.notnull(x) and x.month >= 8 else None  # Start in current year if the debut was in or after August\n",
    ")\n",
    "merged_df['Season End'] = merged_df['Debut Date'].apply(\n",
    "    lambda x: x.year if pd.notnull(x) and x.month <= 7 else None  # End in current year if the debut was in or before July\n",
    ")\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_path = '../data/cleaned/players_merged_NT_stats.csv'  # Specify the output path\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame for verification\n",
    "print(merged_df.head(10))\n",
    "\n",
    "# Confirm that the merged file has been saved successfully\n",
    "print(\"Merged data with 'Season Start' and 'Season End' columns saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for data\n",
    "file_path = '../data/cleaned/players_merged_NT_stats.csv'  # Path to the merged dataset\n",
    "players_file_path = '../data/cleaned/players_incl_ID.csv'  # Path to the players dataset with birthdate information\n",
    "\n",
    "# Load the merged dataset and the players dataset\n",
    "merged_df = pd.read_csv(file_path)\n",
    "players_df = pd.read_csv(players_file_path)\n",
    "\n",
    "# Merge the \"Birthdate\" column from players dataset into the merged dataset\n",
    "merged_df = pd.merge(\n",
    "    merged_df, \n",
    "    players_df[['Player ID', 'Birthdate']], \n",
    "    on='Player ID', \n",
    "    how='left'  # Ensure all rows in merged_df are retained\n",
    ")\n",
    "\n",
    "# Convert the \"Birthdate\" column to a datetime format\n",
    "merged_df['Birthdate'] = pd.to_datetime(\n",
    "    merged_df['Birthdate'], format='%d/%m/%Y', errors='coerce'\n",
    ")\n",
    "\n",
    "# Define a function to calculate missing \"Debut Date\" based on \"Club\" and \"Birthdate\"\n",
    "def calculate_debut_date(row):\n",
    "    if pd.notnull(row['Debut Date']):  # If \"Debut Date\" is already present, retain it\n",
    "        return row['Debut Date']\n",
    "    elif pd.notnull(row['Birthdate']) and pd.notnull(row['Club']):\n",
    "        # Check for youth categories in \"Club\" and calculate the approximate debut date\n",
    "        for category, age_offset in [\n",
    "            ('U15', 14), ('U16', 15), ('U17', 16), ('U18', 17), \n",
    "            ('U19', 18), ('U20', 19), ('U21', 20), ('U22', 21), ('U23', 22)\n",
    "        ]:\n",
    "            if category in row['Club']:\n",
    "                # Add the offset in years to the birthdate to estimate debut date\n",
    "                return row['Birthdate'] + timedelta(days=age_offset * 365.25)\n",
    "    return None  # Return None if no conditions are met\n",
    "\n",
    "# Apply the function to calculate missing \"Debut Dates\"\n",
    "merged_df['Debut Date'] = merged_df.apply(calculate_debut_date, axis=1)\n",
    "\n",
    "# Format \"Debut Date\" column consistently as 'DD/MM/YYYY'\n",
    "merged_df['Debut Date'] = pd.to_datetime(\n",
    "    merged_df['Debut Date']\n",
    ").dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Display the first 20 rows of relevant columns for verification\n",
    "print(merged_df[['Player ID', 'Birthdate', 'Club', 'Debut Date']].head(20))\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "output_path = '../data/cleaned/players_merged_NT_stats.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm that the file has been saved\n",
    "print(\"Updated data with calculated 'Debut Date' saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Season Information  \n",
    "Description\n",
    "This section enriches data with season start and end details where missing values exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the cleaned and merged dataset with Season Start and Season End columns\n",
    "file_path = '../data/cleaned/players_merged_NT_stats.csv'\n",
    "\n",
    "# Load the dataset\n",
    "merged_df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing \"Season End\" where \"Season Start\" is filled\n",
    "merged_df['Season End'] = merged_df.apply(\n",
    "    lambda row: row['Season Start'] + 1 \n",
    "    if pd.notnull(row['Season Start']) and pd.isnull(row['Season End']) \n",
    "    else row['Season End'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Fill missing \"Season Start\" where \"Season End\" is filled\n",
    "merged_df['Season Start'] = merged_df.apply(\n",
    "    lambda row: row['Season End'] - 1 \n",
    "    if pd.notnull(row['Season End']) and pd.isnull(row['Season Start']) \n",
    "    else row['Season Start'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = '../data/cleaned/players_merged_NT_stats.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame for verification\n",
    "print(merged_df.head(10))\n",
    "\n",
    "# Confirm that the updated file has been saved\n",
    "print(\"Data with adjusted 'Season Start' and 'Season End' saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding Competition to Identify National Teams  \n",
    "\n",
    "This section processes the dataset to add competition information, clean empty fields, and remove irrelevant rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the updated file containing merged national team statistics\n",
    "file_path = '../data/cleaned/players_merged_NT_stats.csv'\n",
    "merged_df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Remove rows where the \"Season\" column is blank\n",
    "merged_df = merged_df[merged_df['Season'].notna()]  # Drop rows with NaN in the \"Season\" column\n",
    "merged_df = merged_df[merged_df['Season'] != '']    # Drop rows with empty strings in the \"Season\" column\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "# Remove the \"Season\" and \"Birthdate\" columns as they are no longer required\n",
    "merged_df = merged_df.drop(columns=['Season', 'Birthdate'])\n",
    "\n",
    "# Step 3: Fill missing values in the \"Competition\" column\n",
    "# Replace empty values in the \"Competition\" column with \"International\"\n",
    "merged_df['Competition'] = merged_df['Competition'].fillna('International')\n",
    "\n",
    "# Step 4: Filter out rows where \"Games Played\" has a value of \"-\"\n",
    "# Only keep rows where \"Games Played\" contains valid data\n",
    "merged_df = merged_df[merged_df['Games Played'] != '-']\n",
    "\n",
    "# Save the cleaned and processed DataFrame to a new CSV file\n",
    "output_path = '../data/cleaned/players_merged_stats_NT_cleaned.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame for verification\n",
    "print(merged_df.head(10))\n",
    "\n",
    "# Confirm that the processed file has been saved\n",
    "print(\"Final data with 'Season' column processed and saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleaning Club Player Stats  \n",
    "\n",
    "Clean club player statistics, add missing season information, and ensure uniform formatting for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw players club stats file\n",
    "file_path = '../data/raw/players_club_stats.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if the \"Season\" column exists in the DataFrame\n",
    "if 'Season' in df.columns:\n",
    "    # Step 1: Split the \"Season\" column by \"-\" to separate start and end years\n",
    "    season_split = df['Season'].astype(str).str.split('-', expand=True)\n",
    "    \n",
    "    # Step 2: Create \"Season Start\" and \"Season End\" columns by processing the split values\n",
    "    def convert_year(year):\n",
    "        \"\"\"\n",
    "        Convert short year formats (e.g., 99 or 00) to full years (e.g., 1999 or 2000).\n",
    "        \"\"\"\n",
    "        year = int(year)\n",
    "        if 50 <= year <= 99:  # Assume years in the range 50-99 refer to the 1900s\n",
    "            return 1900 + year\n",
    "        elif 0 <= year <= 49:  # Assume years in the range 0-49 refer to the 2000s\n",
    "            return 2000 + year\n",
    "        return year  # Return the year unchanged if it's already in a valid format\n",
    "\n",
    "    # Apply the conversion function to start and end years\n",
    "    df['Season Start'] = season_split[0].apply(convert_year)\n",
    "    # Use the start year if the end year is missing\n",
    "    df['Season End'] = season_split[1].fillna(season_split[0]).apply(convert_year)\n",
    "\n",
    "    # Step 3: Fill missing values in the \"Competition\" column with \"International\"\n",
    "    df['Competition'] = df['Competition'].fillna('International')\n",
    "\n",
    "    # Step 4: Save the cleaned DataFrame to a new CSV file\n",
    "    output_path = '../data/cleaned/players_club_stats_cleaned.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Display the first few rows of the cleaned DataFrame for verification\n",
    "    print(df.head(10))\n",
    "\n",
    "    # Confirm where the cleaned file has been saved\n",
    "    print(\"Final data with 'Competition' column filled saved to:\", output_path)\n",
    "else:\n",
    "    # Handle the case where the \"Season\" column is not found in the DataFrame\n",
    "    print(\"Error: 'Season' column not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merging and Cleaning Files  \n",
    "\n",
    "Merge club and national team statistics with player details to produce a consolidated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert market values\n",
    "def clean_market_value(value_str):\n",
    "    \"\"\"\n",
    "    Standardizes and converts market values to a consistent format.\n",
    "    Handles 'Mio.' (millions) and 'Tsd.' (thousands) formats.\n",
    "    \"\"\"\n",
    "    value_str = value_str.replace('€', '').replace('â‚¬', '').replace('Tsd.', 'k').replace('Mio.', 'm').replace(',', '.').strip()\n",
    "    market_value = 0.0\n",
    "    if 'm' in value_str:  # If value is in millions\n",
    "        market_value = float(value_str.replace('m', ''))\n",
    "    elif 'k' in value_str:  # If value is in thousands\n",
    "        market_value = float(value_str.replace('k', '')) / 1000  # Convert to millions\n",
    "    return market_value\n",
    "\n",
    "# Function to extract the birthdate from the Birthdate column\n",
    "def extract_birthdate(birthdate_str):\n",
    "    \"\"\"\n",
    "    Extracts the actual birthdate part from a string containing additional details in parentheses.\n",
    "    \"\"\"\n",
    "    birthdate_part, _ = birthdate_str.split('(')\n",
    "    return birthdate_part.strip()\n",
    "\n",
    "# Function to parse a date string into a datetime object\n",
    "def parse_date(date_str, format='%d.%m.%Y'):\n",
    "    \"\"\"\n",
    "    Attempts to parse a date string into a datetime object using the provided format.\n",
    "    Returns NaT if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=format, errors='coerce')\n",
    "    except ValueError:\n",
    "        return pd.NaT\n",
    "\n",
    "# Function to calculate age based on a birthdate\n",
    "def calculate_age(birthdate):\n",
    "    \"\"\"\n",
    "    Calculates the age of a player given their birthdate.\n",
    "    \"\"\"\n",
    "    if pd.notnull(birthdate):\n",
    "        today = datetime.today()\n",
    "        # Calculate age by subtracting years and adjusting for months and days\n",
    "        age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "        return age\n",
    "    return None\n",
    "\n",
    "# Path to the raw data file\n",
    "file_path = '../data/raw/players_NT_2024-11-12.csv'  # Replace with the actual file path if different\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the function to clean and convert market values\n",
    "df['Value'] = df['Value'].apply(clean_market_value)\n",
    "\n",
    "# Extract and parse the birthdate into a consistent format\n",
    "df['Birthdate'] = df['Birthdate'].apply(extract_birthdate).apply(lambda x: parse_date(x, format='%d.%m.%Y'))\n",
    "\n",
    "# Calculate age based on the parsed birthdate\n",
    "df['Age'] = df['Birthdate'].apply(calculate_age)\n",
    "\n",
    "# Remove unnecessary spaces from the 'Name' column\n",
    "df['Name'] = df['Name'].str.strip()\n",
    "\n",
    "# (Optional) Parse other date columns such as 'ContractBegin' and 'ContractEnd'\n",
    "# Uncomment the following lines if these columns exist in your data:\n",
    "# df['ContractBegin'] = df['ContractBegin'].apply(lambda x: parse_date(x, format='%d.%m.%Y'))\n",
    "# df['ContractEnd'] = df['ContractEnd'].apply(lambda x: parse_date(x, format='%d.%m.%Y'))\n",
    "\n",
    "# Save the cleaned and modified DataFrame to a new CSV file\n",
    "output_file_path = '../data/cleaned/players_NT_cleaned.csv'  # Replace with the desired output file name\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the first 10 rows of the cleaned DataFrame for verification\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data files\n",
    "players_merged_stats_nt = pd.read_csv(\"../data/cleaned/players_merged_stats_NT_cleaned.csv\")\n",
    "players_detailed_stats_cleaned = pd.read_csv(\"../data/cleaned/players_club_stats_cleaned.csv\")\n",
    "players_incl_id = pd.read_csv(\"../data/cleaned/players_incl_ID.csv\")\n",
    "players_all_years = pd.read_csv(\"../data/cleaned/players_NT_cleaned.csv\")\n",
    "\n",
    "# Remove the 'insgesamt' column from the club stats DataFrame\n",
    "players_detailed_stats_cleaned = players_detailed_stats_cleaned.drop(columns=['insgesamt'])\n",
    "\n",
    "# Combine the national team stats and club stats DataFrames\n",
    "combined_df = pd.concat([players_merged_stats_nt, players_detailed_stats_cleaned], ignore_index=True)\n",
    "\n",
    "# Drop unnecessary columns 'National Team ID' and 'Position' if they exist\n",
    "combined_df = combined_df.drop(columns=['National Team ID', 'Position'], errors='ignore')\n",
    "\n",
    "# Add additional player information from players_incl_ID DataFrame\n",
    "players_incl_id_selected = players_incl_id[['Player ID', 'Name', 'Position', 'Birthdate']]\n",
    "combined_df = pd.merge(combined_df, players_incl_id_selected, on='Player ID', how='left')\n",
    "\n",
    "# Add market value from players_all_years based on 'Name' and 'Season Start'\n",
    "players_all_years_selected = players_all_years[['Name', 'Year', 'Value']]\n",
    "final_df = pd.merge(\n",
    "    combined_df, \n",
    "    players_all_years_selected, \n",
    "    how='left', \n",
    "    left_on=['Name', 'Season Start'], \n",
    "    right_on=['Name', 'Year']\n",
    ")\n",
    "\n",
    "# Remove the 'Year' column after merging\n",
    "final_df = final_df.drop(columns=['Year'], errors='ignore')\n",
    "\n",
    "# Reorganize columns into the desired order\n",
    "final_df = final_df[\n",
    "    [\n",
    "        'Player ID', 'Name', 'Birthdate', 'Value', 'Competition', 'Type', 'Club', 'Debut Date', \n",
    "        'Season Start', 'Season End', 'Games Played', 'Goals', 'Assists', 'Own Goals', \n",
    "        'Substituted On', 'Substituted Off', 'Yellow Cards', 'Yellow Red', 'Red Cards', \n",
    "        'Penalty Goals', 'Minutes per Goal', 'Goals Conceded', 'Clean Sheets', 'Played Minutes'\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Display the first few rows of the final combined DataFrame for verification\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "output_file_path = \"../data/cleaned/players_combined.csv\"\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved successfully to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Cleaning Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined player data\n",
    "file_path = \"../data/cleaned/players_combined.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to clean and convert numeric columns\n",
    "def clean_numeric_column(column):\n",
    "    \"\"\"\n",
    "    Cleans a numeric column by removing unwanted characters such as quotes,\n",
    "    replacing invalid values, and converting to float.\n",
    "    \"\"\"\n",
    "    return df[column].astype(str).str.replace(\"'\", \"\").str.replace(\".\", \"\").replace('-', '0').fillna('0').astype(float)\n",
    "\n",
    "# Fill empty cells in the 'Value' column with 0 and scale values to millions\n",
    "df['Value'] = df['Value'].fillna(0) * 1000000\n",
    "\n",
    "# List of columns to clean by filling empty or invalid cells with 0 and converting to integers\n",
    "columns_to_fill = [\n",
    "    'Games Played', 'Goals', 'Assists', 'Own Goals', 'Substituted On', 'Substituted Off', \n",
    "    'Yellow Cards', 'Yellow Red', 'Red Cards', 'Penalty Goals', 'Minutes per Goal', \n",
    "    'Goals Conceded', 'Clean Sheets', 'Played Minutes'\n",
    "]\n",
    "\n",
    "# Apply the cleaning function to each column in the list and convert the results to integers\n",
    "for column in columns_to_fill:\n",
    "    df[column] = clean_numeric_column(column)\n",
    "    df[column] = df[column].astype(int)\n",
    "\n",
    "# Convert 'Debut Date' and 'Birthdate' columns to datetime format\n",
    "df['Debut Date'] = pd.to_datetime(df['Debut Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df['Birthdate'] = pd.to_datetime(df['Birthdate'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Check for null values in 'Debut Date' and 'Birthdate' after conversion\n",
    "print(\"\\nNull values after converting 'Debut Date' and 'Birthdate' to datetime:\")\n",
    "print(df[['Debut Date', 'Birthdate']].isnull().sum())\n",
    "\n",
    "# Adjust 'Season Start' based on the 'Debut Date' month\n",
    "# If the month is January to July, set 'Season Start' to the previous year\n",
    "# If the month is August to December, set 'Season Start' to the year of 'Debut Date'\n",
    "df['Season Start'] = df.apply(\n",
    "    lambda row: row['Debut Date'].year - 1 if pd.notnull(row['Debut Date']) and pd.isnull(row['Season Start']) and row['Debut Date'].month <= 7 else \n",
    "                (row['Debut Date'].year if pd.notnull(row['Debut Date']) and pd.isnull(row['Season Start']) and row['Debut Date'].month >= 8 else row['Season Start']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Fill 'Season End' as 'Season Start' + 1 if 'Season End' is missing\n",
    "df['Season End'] = df.apply(\n",
    "    lambda row: row['Season Start'] + 1 if pd.notnull(row['Season Start']) and pd.isnull(row['Season End']) else row['Season End'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verify the correctness of 'Season Start' and 'Season End' columns\n",
    "print(\"\\nChecking 'Season Start' and 'Season End' after filling logic:\")\n",
    "print(df[['Player ID', 'Debut Date', 'Season Start', 'Season End']].isnull().sum())\n",
    "\n",
    "# Calculate 'Age in Season' using the 'Birthdate' and 'Season Start'\n",
    "df['Birth Year'] = df['Birthdate'].dt.year\n",
    "df['Age in Season'] = df['Season Start'] - df['Birth Year']\n",
    "\n",
    "# Check for missing values in 'Age in Season'\n",
    "print(\"\\nMissing 'Age in Season' values:\")\n",
    "missing_age_rows = df[df['Age in Season'].isnull()]\n",
    "print(missing_age_rows[['Player ID', 'Birthdate', 'Season Start', 'Age in Season']])\n",
    "\n",
    "# Remove the helper column 'Birth Year' after calculation\n",
    "df = df.drop(columns=['Birth Year'])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "cleaned_file_path = \"../data/cleaned/players_combined_cleaned.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Confirm that the cleaned data has been saved\n",
    "print(f\"\\nCleaned data saved to: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Grouping Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the cleaned player dataset\n",
    "file_path = \"../data/cleaned/players_combined_cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill empty cells in the 'Type' column with the default value 'Nationalteam'\n",
    "df['Type'] = df['Type'].fillna('Nationalteam')\n",
    "\n",
    "# Verify that all missing values in 'Type' are filled\n",
    "print(\"Number of missing values in 'Type' after filling:\", df['Type'].isnull().sum())\n",
    "\n",
    "# Replace values in the 'Competition' column for \"1. Liga CH\"\n",
    "df['Competition'] = df['Competition'].replace({\n",
    "    '1. Liga Gr. 1': '1. Liga CH',\n",
    "    '1. Liga Gr. 2': '1. Liga CH',\n",
    "    '1. Liga Gr. 3': '1. Liga CH',\n",
    "    '1. Liga Gr. 1 (- 11/12)': '1. Liga CH',\n",
    "    '1 . Liga Gr. 2 (- 11/12)': '1. Liga CH',\n",
    "    '1. Liga Gr. 3 (- 11/12)': '1. Liga CH',\n",
    "    '1. Liga Playoff': '1. Liga CH'\n",
    "})\n",
    "\n",
    "# Replace values in the 'Competition' column for \"2. Liga Inter CH\"\n",
    "df['Competition'] = df['Competition'].replace({\n",
    "    '2. Liga Inter - Gr. 1': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 2': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 3': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 4': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 5': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 6': '2. Liga Inter CH',\n",
    "    '2. Liga inter - Gr. 1 (- 11/12)': '2. Liga Inter CH',\n",
    "    '2. Liga inter - Gr. 3 (- 11/12)': '2. Liga Inter CH',\n",
    "    '2. Liga inter - Gr. 4 (- 11/12)': '2. Liga Inter CH',\n",
    "    '2. Liga inter - Gr. 5 (- 11/12)': '2. Liga Inter CH',\n",
    "    '2. Liga Inter - Gr. 6 (- 21/22)': '2. Liga Inter CH',\n",
    "    '2. Liga': '2. Liga Inter CH'\n",
    "})\n",
    "\n",
    "# Verify that replacements in 'Competition' were successful\n",
    "print(\"Unique values in 'Competition' after replacements:\")\n",
    "print(df['Competition'].unique())\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = \"../data/cleaned/players_combined_cleaned_updated.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the updated file has been saved\n",
    "print(f\"The file has been successfully updated and saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleaning and Merging Market Values  \n",
    "\n",
    "Standardize market values, fill missing data, and calculate player ages for consistent comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current date for dynamic file path\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "input_path = f'../data/raw/market_values_{current_date}.csv'\n",
    "players_path = '../data/cleaned/players_incl_ID.csv'\n",
    "output_path = f'../data/cleaned/market_values_{current_date}_cleaned.csv'\n",
    "\n",
    "# Load the market values data\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Load the players data to include \"Birthdate\"\n",
    "players_df = pd.read_csv(players_path)\n",
    "\n",
    "# Standardize column names for merging\n",
    "players_df.rename(columns={'Player ID': 'Player_ID'}, inplace=True)\n",
    "\n",
    "# Merge the market values data with players' birthdate data using 'Player_ID'\n",
    "df = df.merge(players_df[['Player_ID', 'Birthdate']], on='Player_ID', how='left')\n",
    "\n",
    "# Function to standardize the birthdate format to 'dd.mm.yyyy'\n",
    "def standardize_birthdate(birthdate):\n",
    "    try:\n",
    "        return pd.to_datetime(birthdate, dayfirst=True).strftime('%d.%m.%Y')\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the date conversion function for the 'Birthdate' column\n",
    "df['Birthdate'] = df['Birthdate'].apply(standardize_birthdate)\n",
    "\n",
    "# Function to handle various formats in the 'Market_Value' column and normalize the values\n",
    "def convert_market_value(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan  # Keep NaN values as is\n",
    "\n",
    "    # If the value is already numeric, return it\n",
    "    if isinstance(value, (int, float)):\n",
    "        return value\n",
    "\n",
    "    # Clean and standardize string values\n",
    "    value = value.strip().replace(\"â‚¬\", \"\").replace(\"€\", \"\").replace(\"Aktueller Marktwert:\", \"\").strip()\n",
    "\n",
    "    # Convert \"-\" to 0\n",
    "    if value == \"-\":\n",
    "        return 0\n",
    "\n",
    "    # Extract numeric value from strings with \"Mio.\" or \"Tsd.\" and convert accordingly\n",
    "    try:\n",
    "        if \"Mio\" in value:\n",
    "            number_str = re.search(r\"(\\d+[,.]?\\d*)\", value).group()\n",
    "            number = float(number_str.replace(\",\", \".\")) * 1_000_000\n",
    "            return number\n",
    "        elif \"Tsd\" in value:\n",
    "            number_str = re.search(r\"(\\d+[,.]?\\d*)\", value).group()\n",
    "            number = float(number_str.replace(\",\", \".\")) * 1_000\n",
    "            return number\n",
    "        else:\n",
    "            # Assume it's in euros if no unit is specified\n",
    "            number_str = re.search(r\"(\\d+[,.]?\\d*)\", value).group()\n",
    "            number = float(number_str.replace(\",\", \".\"))\n",
    "            return number\n",
    "    except (AttributeError, ValueError):\n",
    "        return np.nan  # Return NaN if no valid number is found\n",
    "\n",
    "# Apply the function to clean the 'Market_Value' column\n",
    "df['Market_Value'] = df['Market_Value'].apply(convert_market_value)\n",
    "\n",
    "# Function to standardize the 'Date' column to 'dd.mm.yyyy' format\n",
    "def standardize_date(date):\n",
    "    try:\n",
    "        return pd.to_datetime(date, dayfirst=True).strftime('%d.%m.%Y')\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the date standardization function\n",
    "df['Date'] = df['Date'].apply(standardize_date)\n",
    "\n",
    "# Function to calculate age if 'Age' is missing but 'Date' and 'Birthdate' are available\n",
    "def calculate_age(birthdate, current_date):\n",
    "    if pd.isna(birthdate) or pd.isna(current_date):\n",
    "        return np.nan\n",
    "    birthdate = pd.to_datetime(birthdate, dayfirst=True)\n",
    "    current_date = pd.to_datetime(current_date, dayfirst=True)\n",
    "    return current_date.year - birthdate.year - ((current_date.month, current_date.day) < (birthdate.month, birthdate.day))\n",
    "\n",
    "# Apply age calculation for missing 'Age' values\n",
    "df['Age'] = df.apply(lambda row: row['Age'] if not pd.isna(row['Age']) else calculate_age(row['Birthdate'], row['Date']), axis=1)\n",
    "\n",
    "# Set 'Market_Value' to 0 where both 'Date' and 'Age' are present, but 'Market_Value' is missing\n",
    "df.loc[(~df['Date'].isna()) & (~df['Age'].isna()) & (df['Market_Value'].isna()), 'Market_Value'] = 0\n",
    "\n",
    "# Drop rows where 'Date' or 'Market_Value' are still missing\n",
    "df = df.dropna(subset=['Date', 'Market_Value'])\n",
    "\n",
    "# Select only relevant columns for the final output\n",
    "df = df[['Player_ID', 'Date', 'Age', 'Market_Value', 'Birthdate']]\n",
    "\n",
    "# Display the processed DataFrame for verification\n",
    "print(\"\\nFinal DataFrame with standardized Date, Market_Value, Birthdate, and calculated Age:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the cleaned DataFrame to the specified output path\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the final output file has been saved\n",
    "print(f\"\\nFinal cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Market Values for all Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current date and file paths\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "market_values_path = f'../data/raw/market_values_{current_date}_cleaned.csv'\n",
    "players_path = '../data/cleaned/players_incl_ID.csv'\n",
    "output_path = f'../data/cleaned/market_values_{current_date}_extended.csv'\n",
    "\n",
    "# Load the market values data and players data\n",
    "market_values_df = pd.read_csv(market_values_path)\n",
    "players_df = pd.read_csv(players_path)\n",
    "\n",
    "# Rename 'Player ID' to 'Player_ID' in players_df to match the market_values_df column\n",
    "players_df.rename(columns={'Player ID': 'Player_ID'}, inplace=True)\n",
    "\n",
    "# Print columns to verify the alignment of data for merging\n",
    "print(\"Columns in players_df:\", players_df.columns)\n",
    "print(\"Columns in market_values_df:\", market_values_df.columns)\n",
    "\n",
    "# Convert the 'Date' column in the market values dataset to datetime format for calculations\n",
    "market_values_df['Date'] = pd.to_datetime(market_values_df['Date'], dayfirst=True)\n",
    "\n",
    "# Identify the latest date in the market values data for reference\n",
    "latest_date = market_values_df['Date'].max()\n",
    "latest_date_str = latest_date.strftime('%d.%m.%Y')\n",
    "\n",
    "# Convert 'Birthdate' in the players dataset to datetime format\n",
    "players_df['Birthdate'] = pd.to_datetime(players_df['Birthdate'], dayfirst=True)\n",
    "\n",
    "# Calculate the maximum age of each player as of the latest date in the market values data\n",
    "players_df['Max_Age'] = players_df['Birthdate'].apply(\n",
    "    lambda x: latest_date.year - x.year - ((latest_date.month, latest_date.day) < (x.month, x.day))\n",
    ")\n",
    "\n",
    "# Merge players' data with market values data to ensure all players are included\n",
    "# Using suffixes to distinguish columns during the merge\n",
    "full_df = pd.merge(\n",
    "    players_df[['Player_ID', 'Birthdate', 'Max_Age']],\n",
    "    market_values_df,\n",
    "    on='Player_ID',\n",
    "    how='left',\n",
    "    suffixes=('_player', '_market')\n",
    ")\n",
    "\n",
    "# Use the 'Birthdate_player' column as the primary birthdate and drop redundant columns\n",
    "full_df['Birthdate'] = full_df['Birthdate_player']\n",
    "full_df = full_df.drop(columns=['Birthdate_player', 'Birthdate_market'], errors='ignore')\n",
    "\n",
    "# Ensure 'Birthdate' exists in the final DataFrame, raise an error if missing\n",
    "if 'Birthdate' not in full_df.columns:\n",
    "    print(\"Columns after processing:\", full_df.columns)\n",
    "    raise KeyError(\"The 'Birthdate' column is missing from the final DataFrame.\")\n",
    "\n",
    "# Define a function to fill missing ages by generating rows for the entire age range\n",
    "def fill_missing_ages(group):\n",
    "    # Generate a DataFrame for the full age range (14 to max age for the player)\n",
    "    max_age = group['Max_Age'].iloc[0]\n",
    "    full_age_range = pd.DataFrame({'Age': range(14, max_age + 1)})\n",
    "    \n",
    "    # Merge the age range with the player's existing data\n",
    "    merged_df = full_age_range.merge(group, on='Age', how='left')\n",
    "    \n",
    "    # Fill missing fields with appropriate values\n",
    "    merged_df['Player_ID'] = group['Player_ID'].iloc[0]\n",
    "    merged_df['Birthdate'] = group['Birthdate'].iloc[0]\n",
    "    merged_df['Date'] = merged_df['Date'].fillna(latest_date_str)\n",
    "    merged_df['Market_Value'] = merged_df['Market_Value'].fillna(0)  # Set missing market values to 0\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Apply the function to generate rows for missing ages for each player\n",
    "filled_df = full_df.groupby('Player_ID').apply(fill_missing_ages).reset_index(drop=True)\n",
    "\n",
    "# Select only the relevant columns for the final output\n",
    "filled_df = filled_df[['Player_ID', 'Date', 'Age', 'Market_Value', 'Birthdate']]\n",
    "\n",
    "# Display the resulting DataFrame for verification\n",
    "print(\"\\nFinal DataFrame with filled age rows and Market_Value set to 0 where missing:\")\n",
    "print(filled_df.head())  # Adjust to view more rows if needed\n",
    "\n",
    "# Save the final DataFrame to the output file\n",
    "filled_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the data has been saved\n",
    "print(f\"\\nFilled data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completing market values based on preceding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current date and file paths\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')  # Format the current date dynamically\n",
    "market_values_path = f'../data/cleaned/market_values_2024-11-15_cleaned.csv'  # Path to the cleaned market values file\n",
    "players_path = '../data/cleaned/players_incl_ID.csv'  # Path to the players' data file\n",
    "output_path = f'../data/cleaned/market_values_{current_date}_extended.csv'  # Output path for the extended market values file\n",
    "\n",
    "# Load the market values data and players data\n",
    "market_values_df = pd.read_csv(market_values_path)  # Load the market values file\n",
    "players_df = pd.read_csv(players_path)  # Load the players file\n",
    "\n",
    "# Rename 'Player ID' to 'Player_ID' in players_df to match the column name in market_values_df\n",
    "players_df.rename(columns={'Player ID': 'Player_ID'}, inplace=True)\n",
    "\n",
    "# Print the columns in both DataFrames to ensure alignment before merging\n",
    "print(\"Columns in players_df:\", players_df.columns)\n",
    "print(\"Columns in market_values_df:\", market_values_df.columns)\n",
    "\n",
    "# Convert the 'Date' column in the market values data to datetime format\n",
    "market_values_df['Date'] = pd.to_datetime(market_values_df['Date'], dayfirst=True)\n",
    "\n",
    "# Identify the latest date in the market values data for reference\n",
    "latest_date = market_values_df['Date'].max()\n",
    "latest_date_str = latest_date.strftime('%d.%m.%Y')  # Format the latest date as a string in 'dd.mm.yyyy'\n",
    "\n",
    "# Convert the 'Birthdate' column in the players data to datetime format\n",
    "players_df['Birthdate'] = pd.to_datetime(players_df['Birthdate'], dayfirst=True)\n",
    "\n",
    "# Calculate the maximum age of each player as of the latest date\n",
    "players_df['Max_Age'] = players_df['Birthdate'].apply(\n",
    "    lambda x: latest_date.year - x.year - ((latest_date.month, latest_date.day) < (x.month, x.day))\n",
    ")\n",
    "\n",
    "# Merge the players' data with the market values data, ensuring all players are included\n",
    "full_df = pd.merge(\n",
    "    players_df[['Player_ID', 'Birthdate', 'Max_Age']],  # Only include necessary columns from players_df\n",
    "    market_values_df,  # Merge with market values data\n",
    "    on='Player_ID',  # Merge on Player_ID\n",
    "    how='left',  # Include all players, even if no market value data is available\n",
    "    suffixes=('_player', '_market')  # Distinguish overlapping columns with suffixes\n",
    ")\n",
    "\n",
    "# Use 'Birthdate_player' as the primary birthdate column and drop redundant columns\n",
    "full_df['Birthdate'] = full_df['Birthdate_player']\n",
    "full_df = full_df.drop(columns=['Birthdate_player', 'Birthdate_market'], errors='ignore')\n",
    "\n",
    "# Ensure that the 'Birthdate' column exists in the final DataFrame\n",
    "if 'Birthdate' not in full_df.columns:\n",
    "    print(\"Columns after processing:\", full_df.columns)\n",
    "    raise KeyError(\"The 'Birthdate' column is missing from the final DataFrame.\")\n",
    "\n",
    "# Define a function to fill missing ages for each player\n",
    "def fill_missing_ages(group):\n",
    "    # Generate the full range of ages from 14 to the player's maximum age\n",
    "    max_age = group['Max_Age'].iloc[0]\n",
    "    full_age_range = pd.DataFrame({'Age': range(14, max_age + 1)})\n",
    "    \n",
    "    # Merge the full age range with the player's existing data\n",
    "    merged_df = full_age_range.merge(group, on='Age', how='left')\n",
    "    \n",
    "    # Fill missing 'Player_ID' and 'Birthdate' values\n",
    "    merged_df['Player_ID'] = group['Player_ID'].iloc[0]\n",
    "    merged_df['Birthdate'] = group['Birthdate'].iloc[0]\n",
    "    merged_df['Date'] = merged_df['Date'].fillna(latest_date_str)  # Fill missing dates with the latest date\n",
    "    \n",
    "    # Fill missing Market_Value with the last recorded value (forward fill)\n",
    "    merged_df['Market_Value'] = merged_df['Market_Value'].fillna(method='ffill')\n",
    "    \n",
    "    # Set any remaining missing Market_Value to 0\n",
    "    merged_df['Market_Value'] = merged_df['Market_Value'].fillna(0)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Apply the function to each player's data, ensuring all ages from 14 to max age are included\n",
    "filled_df = full_df.groupby('Player_ID').apply(fill_missing_ages).reset_index(drop=True)\n",
    "\n",
    "# Retain only relevant columns for the final output\n",
    "filled_df = filled_df[['Player_ID', 'Date', 'Age', 'Market_Value', 'Birthdate']]\n",
    "\n",
    "# Display the resulting DataFrame for verification\n",
    "print(\"\\nFinal DataFrame with filled age rows and Market_Value updated:\")\n",
    "print(filled_df.head())  # Preview the first few rows of the DataFrame\n",
    "\n",
    "# Save the extended DataFrame to a new output file\n",
    "filled_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the data has been saved successfully\n",
    "print(f\"\\nFilled data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "players_file = \"../data/cleaned/players_combined_cleaned_updated.csv\"  # Path to the cleaned players data\n",
    "market_values_file = \"../data/cleaned/market_values_2024-11-18_extended.csv\"  # Path to the extended market values data\n",
    "player_incl_id_file = \"../data/cleaned/players_incl_ID.csv\"  # Path to the player details file\n",
    "\n",
    "# Step 1: Load the market values data\n",
    "market_values_df = pd.read_csv(market_values_file)\n",
    "\n",
    "# Step 2: Drop 'Date' and 'Birthdate' columns\n",
    "# These columns are not required for the merging process and analysis\n",
    "market_values_df = market_values_df.drop(columns=['Date', 'Birthdate'], errors='ignore')\n",
    "\n",
    "# Step 3: Group by 'Player_ID' and 'Age' to calculate the average market value for each age\n",
    "market_values_avg = market_values_df.groupby(['Player_ID', 'Age'])['Market_Value'].mean().reset_index()\n",
    "\n",
    "# Step 4: Create a helper column for the last recorded value of 'Market_Value' for each player and age\n",
    "# This is done using forward fill within each player group to retain historical market value data\n",
    "market_values_avg = market_values_avg.sort_values(by=['Player_ID', 'Age'])\n",
    "market_values_avg['Last_Recorded_Value'] = market_values_avg.groupby('Player_ID')['Market_Value'].ffill()\n",
    "\n",
    "# Step 5: Load the cleaned players data and remove duplicate rows\n",
    "players_df = pd.read_csv(players_file)\n",
    "players_df.drop_duplicates(inplace=True)  # Ensure no duplicate rows exist in the data\n",
    "\n",
    "# Step 6: Merge the players data with the market values\n",
    "# Perform a left join on 'Player ID' and 'Age in Season' to align the market values with player data\n",
    "merged_df = pd.merge(\n",
    "    players_df,\n",
    "    market_values_avg,\n",
    "    how='left',\n",
    "    left_on=['Player ID', 'Age in Season'],\n",
    "    right_on=['Player_ID', 'Age']\n",
    ")\n",
    "\n",
    "# Step 7: Handle missing values in 'Market_Value'\n",
    "# Use 'Last_Recorded_Value' to fill missing values in 'Market_Value'\n",
    "merged_df['Market_Value'] = merged_df['Market_Value'].combine_first(merged_df['Last_Recorded_Value'])\n",
    "merged_df['Market_Value'] = merged_df['Market_Value'].fillna(0)  # Replace any remaining missing values with 0\n",
    "\n",
    "# Drop unnecessary columns that are no longer required for analysis\n",
    "merged_df = merged_df.drop(columns=['Age', 'Player_ID', 'Last_Recorded_Value', 'Value'], errors='ignore')\n",
    "\n",
    "# Step 8: Load the player details file to include the 'Position' column\n",
    "player_incl_id_df = pd.read_csv(player_incl_id_file)\n",
    "\n",
    "# Step 9: Merge the 'Position' column into the merged DataFrame\n",
    "# Use 'Player ID' as the key to bring position data into the final DataFrame\n",
    "merged_with_position = pd.merge(\n",
    "    merged_df,\n",
    "    player_incl_id_df[['Player ID', 'Position']],\n",
    "    how='left',\n",
    "    on='Player ID'\n",
    ")\n",
    "\n",
    "# Step 10: Save the updated DataFrame to a new CSV file\n",
    "output_file = \"../data/cleaned/players_complete.csv\"  # Path to save the final DataFrame\n",
    "merged_with_position.to_csv(output_file, index=False)\n",
    "\n",
    "# Print confirmation of successful saving\n",
    "print(f\"Final processed data with positions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Separate National Team Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "players_complete_file = \"../data/cleaned/players_complete.csv\"  # Path to the cleaned players dataset\n",
    "\n",
    "# Step 1: Load the players dataset\n",
    "players_df = pd.read_csv(players_complete_file)  # Load the players data for further processing\n",
    "\n",
    "# Step 2: Define a function to determine the 'Category' based on 'Type' and 'Club'\n",
    "import re  # Import the regex module for pattern matching\n",
    "\n",
    "def determine_category(row):\n",
    "    \"\"\"\n",
    "    Determines the category of a player based on their 'Type' and 'Club'.\n",
    "\n",
    "    If the 'Type' is 'Nationalteam':\n",
    "    - Extract the U-level (e.g., 'U15', 'U17') from the 'Club' using regex if present.\n",
    "    - If no U-level is found, categorize as 'A Nationalteam'.\n",
    "    For non-national teams, the category remains None.\n",
    "\n",
    "    Args:\n",
    "        row: A row of the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        str: The category of the player.\n",
    "    \"\"\"\n",
    "    if row['Type'] == 'Nationalteam':  # Check if the player belongs to the national team\n",
    "        if 'U' in row['Club']:  # Check if the club contains a U-level (e.g., U15, U21)\n",
    "            # Use regex to extract \"U\" followed by digits (e.g., 'U15', 'U17')\n",
    "            match = re.search(r'U\\d+', row['Club'])\n",
    "            if match:\n",
    "                return match.group(0)  # Return the matched U-level\n",
    "        else:\n",
    "            return 'A Nationalteam'  # Default to 'A Nationalteam' for senior players\n",
    "    return None  # Return None for non-national team players\n",
    "\n",
    "# Step 3: Apply the function to create a new 'Category' column\n",
    "# Apply the determine_category function to each row of the DataFrame\n",
    "players_df['Category'] = players_df.apply(determine_category, axis=1)\n",
    "\n",
    "# Step 4: Save the updated DataFrame to a new CSV file\n",
    "output_file = \"../data/cleaned/players_complete.csv\"  # Path to save the updated dataset\n",
    "players_df.to_csv(output_file, index=False)  # Save the DataFrame without including the index\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Updated data with fixed 'Category' column saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Add Top 5 Competition Yes/No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First clean Bundesliga Germany / Bundesliga AUT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "players_complete_file = \"../data/cleaned/players_complete.csv\"  # Path to the cleaned players dataset\n",
    "\n",
    "# Load the players_complete.csv file\n",
    "players_df = pd.read_csv(players_complete_file)  # Load the players data for further processing\n",
    "\n",
    "# List of Bundesliga AUT clubs\n",
    "# A predefined list of Austrian Bundesliga clubs to differentiate from the German Bundesliga\n",
    "bundesliga_aut_clubs = [\n",
    "    \"FC Blau-Weiß Linz\", \"FC Wacker Innsbruck\", \"FK Austria Wien\", \n",
    "    \"LASK\", \"SCR Altach\", \"SK Rapid Wien\", \"SK Sturm Graz\", \n",
    "    \"Red Bull Salzburg\", \"SV Ried\"\n",
    "]\n",
    "\n",
    "# Step 1: Define a function to clean the \"Competition\" column\n",
    "def clean_competition(row):\n",
    "    \"\"\"\n",
    "    Adjusts the 'Competition' column to distinguish between German Bundesliga and Austrian Bundesliga.\n",
    "    \n",
    "    Args:\n",
    "        row: A row of the DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        str: Updated competition name.\n",
    "    \"\"\"\n",
    "    if row['Competition'] == \"Bundesliga\" and row['Club'] in bundesliga_aut_clubs:\n",
    "        return \"Bundesliga AUT\"  # Mark as Austrian Bundesliga\n",
    "    return row['Competition']  # Retain original competition otherwise\n",
    "\n",
    "# Step 2: Apply the function to update the \"Competition\" column\n",
    "players_df['Competition'] = players_df.apply(clean_competition, axis=1)\n",
    "\n",
    "# Step 4: Define a list of top 5 competitions\n",
    "# The top-tier European leagues to be identified in the dataset\n",
    "top_5_competitions = [\"Serie A\", \"Bundesliga\", \"Ligue 1\", \"Premier League\", \"LaLiga\"]\n",
    "\n",
    "# Step 5: Define a function to determine if the competition is in the Top 5\n",
    "def is_top_5(competition):\n",
    "    \"\"\"\n",
    "    Determines if the competition is one of the top 5 leagues.\n",
    "    \n",
    "    Args:\n",
    "        competition (str): The competition name.\n",
    "        \n",
    "    Returns:\n",
    "        str: \"Yes\" if the competition is in the top 5, otherwise \"No\".\n",
    "    \"\"\"\n",
    "    return \"Yes\" if competition in top_5_competitions else \"No\"\n",
    "\n",
    "# Step 6: Apply the function to create a new 'Top 5' column\n",
    "players_df['Top 5'] = players_df['Competition'].apply(is_top_5)\n",
    "\n",
    "# Step 8: Define a function to determine if the player is in the A Nationalteam\n",
    "def is_a_nationalteam(category):\n",
    "    \"\"\"\n",
    "    Identifies if the player is part of the A Nationalteam.\n",
    "    \n",
    "    Args:\n",
    "        category (str): The player's category (e.g., \"A Nationalteam\").\n",
    "        \n",
    "    Returns:\n",
    "        str: \"Yes\" if in A Nationalteam, otherwise \"No\".\n",
    "    \"\"\"\n",
    "    return \"Yes\" if category == \"A Nationalteam\" else \"No\"\n",
    "\n",
    "# Step 9: Apply the function to create a new 'A Nationalteam' column\n",
    "players_df['A Nationalteam'] = players_df['Category'].apply(is_a_nationalteam)\n",
    "\n",
    "# Step 11: Define a function to determine the general position\n",
    "def determine_general_position(position):\n",
    "    \"\"\"\n",
    "    Maps specific positions to generalized categories (e.g., Goalkeeper, Defender).\n",
    "    \n",
    "    Args:\n",
    "        position (str): The player's specific position.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generalized position category.\n",
    "    \"\"\"\n",
    "    if position == \"Torwart\":\n",
    "        return \"Goalkeeper\"\n",
    "    elif position in [\"Linker Verteidiger\", \"Innenverteidiger\", \"Rechter Verteidiger\", \"Abwehr\"]:\n",
    "        return \"Defender\"\n",
    "    elif position in [\"Defensives Mittelfeld\", \"Linkes Mittelfeld\", \"Rechtes Mittelfeld\", \"Zentrales Mittelfeld\", \"Offensives Mittelfeld\", \"Mittelfeld\"]:\n",
    "        return \"Midfielder\"\n",
    "    elif position in [\"Hängende Spitze\", \"Linksaußen\", \"Rechtsaußen\", \"Mittelstürmer\", \"Sturm\"]:\n",
    "        return \"Forward\"\n",
    "    return \"Unknown\"  # Default category for unexpected positions\n",
    "\n",
    "# Step 12: Apply the function to create the 'General Position' column\n",
    "players_df['General Position'] = players_df['Position'].apply(determine_general_position)\n",
    "\n",
    "# Step 3: Save the updated DataFrame back to a CSV file\n",
    "output_file = \"../data/cleaned/players_complete.csv\"  # Path to save the updated dataset\n",
    "players_df.to_csv(output_file, index=False)  # Save the DataFrame without including the index\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Updated data with cleaned 'Competition' column saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Grouping into Swiss / Foreign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/cleaned/players_complete.csv'  # Path to the cleaned players dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define a list of competitions that belong to Swiss football leagues\n",
    "swiss_competitions = [\n",
    "    \"1. Liga CH\", \"Super League\", \"Challenge League\", \"Challenge League Barrage\", \"2. Liga Inter CH\",\n",
    "    \"U17 Elite League\", \"U17 Elite Platzierungsspiele\", \"U17 Elite Playoffs\", \"U17 Elite Playouts\",\n",
    "    \"U18 Elite League\", \"U18 Elite Platzierungsspiele\", \"U18 Elite Playoffs\", \"U18 Elite Playouts\",\n",
    "    \"U19 Elite League\", \"U19 Elite Platzierungsspiele\", \"U19 Elite Playoffs\", \"U19 Elite Playouts\",\n",
    "    \"U21 PL Elite Gruppe\",\n",
    "    \"Promotion League\", \"Promotion League - Abstiegsr.\", \"Promotion League - Aufstiegsr.\", \"Promotion League - Quali\",\n",
    "    \"Super League Barrage\", \"Super League Play-off\", \"Super League Play-out\"\n",
    "]\n",
    "\n",
    "# Step 1: Create a new column \"Country\"\n",
    "def assign_country(competition):\n",
    "    \"\"\"\n",
    "    Assigns the country based on the competition.\n",
    "    \n",
    "    Args:\n",
    "        competition (str): The competition name.\n",
    "    \n",
    "    Returns:\n",
    "        str: The assigned country (\"Swiss\", \"Foreign\", or \"N/A\").\n",
    "    \"\"\"\n",
    "    if competition in swiss_competitions:\n",
    "        return \"Swiss\"\n",
    "    elif competition == \"International\":\n",
    "        return \"N/A\"\n",
    "    else:\n",
    "        return \"Foreign\"\n",
    "\n",
    "df['Country'] = df['Competition'].apply(assign_country)\n",
    "\n",
    "# Step 2: Create a new column \"Level\"\n",
    "def assign_level(row):\n",
    "    \"\"\"\n",
    "    Assigns the level (e.g., Academy, Active, or N/A) based on the club and type.\n",
    "    \n",
    "    Args:\n",
    "        row: A row of the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        str: The assigned level.\n",
    "    \"\"\"\n",
    "    if row['Type'] == 'Nationalteam':\n",
    "        return \"N/A\"\n",
    "    elif any(f\"U{age}\" in row['Club'] for age in range(15, 24)):\n",
    "        return \"Academy\"\n",
    "    else:\n",
    "        return \"Active\"\n",
    "\n",
    "df['Level'] = df.apply(assign_level, axis=1)\n",
    "\n",
    "# Step 3: Identify clubs that participated in Swiss competitions\n",
    "clubs_in_swiss_competitions = df[df['Competition'].isin(swiss_competitions)]['Club'].unique()\n",
    "\n",
    "# Update \"Country\" for rows where the club is in the identified Swiss clubs list\n",
    "df['Country'] = df.apply(\n",
    "    lambda row: \"Swiss\" if row['Club'] in clubs_in_swiss_competitions else row['Country'], axis=1\n",
    ")\n",
    "\n",
    "# Step 4: Combine \"Country\" and \"Level\" into a new column \"Country_Level\"\n",
    "def combine_country_and_level(row):\n",
    "    \"\"\"\n",
    "    Combines the 'Country' and 'Level' columns into a single column.\n",
    "    \n",
    "    Args:\n",
    "        row: A row of the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        str: The combined value of country and level, or \"N/A\" if either is \"N/A\".\n",
    "    \"\"\"\n",
    "    if row['Country'] == \"N/A\" or row['Level'] == \"N/A\":\n",
    "        return \"N/A\"\n",
    "    else:\n",
    "        return f\"{row['Country']} - {row['Level']}\"\n",
    "\n",
    "df['Country_Level'] = df.apply(combine_country_and_level, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '../data/cleaned/players_complete_updated.csv'  # Output path for the updated dataset\n",
    "df.to_csv(output_file, index=False)  # Save without including the index\n",
    "\n",
    "# Confirm the dataset has been saved\n",
    "print(f\"Filtered dataset with 'Country' and 'Country_Level' columns saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Get Similar Players "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data\n",
    "file_path = '../data/cleaned/players_completed.csv'  # Load the updated cleaned players dataset\n",
    "players_df = pd.read_csv(file_path)\n",
    "\n",
    "# Define numeric features for similarity calculations\n",
    "features = [\n",
    "    'Games Played', 'Goals', 'Assists', 'Yellow Cards', 'Red Cards',\n",
    "    'Penalty Goals', 'Minutes per Goal', 'Goals Conceded', 'Clean Sheets',\n",
    "    'Played Minutes'\n",
    "]\n",
    "players_df[features] = players_df[features].fillna(0)  # Fill NaN values with 0 for numerical stability\n",
    "\n",
    "# Encode categorical features: 'Competition', 'General Position', and 'Country_Level'\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Use OneHotEncoder to convert categorical data to binary\n",
    "encoded = encoder.fit_transform(players_df[['Competition', 'General Position', 'Country_Level']])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded,\n",
    "    columns=encoder.get_feature_names_out(['Competition', 'General Position', 'Country_Level'])  # Add meaningful column names\n",
    ")\n",
    "\n",
    "# Convert 'Top 5' column to binary (1 for 'Yes', 0 for 'No')\n",
    "players_df['Top 5'] = players_df['Top 5'].map({'Yes': 1, 'No': 0}).fillna(0)\n",
    "\n",
    "# Combine encoded categorical features back into the DataFrame\n",
    "players_df = pd.concat([players_df.reset_index(drop=True), encoded_df], axis=1)\n",
    "\n",
    "# Filter baseline players belonging to the 'A Nationalteam'\n",
    "baseline_players = players_df[players_df['Category'] == 'A Nationalteam']\n",
    "\n",
    "# Filter rows where 'Age in Season' is below 22 for both baseline and all players\n",
    "baseline_players = baseline_players[baseline_players['Age in Season'] < 22]\n",
    "players_df = players_df[players_df['Age in Season'] < 22]\n",
    "\n",
    "# Calculate total occurrences of \"Top 5\" competitions per player per Age in Season\n",
    "top_5_totals = (\n",
    "    players_df.groupby(['Player ID', 'Age in Season'])['Top 5']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Top 5': 'Top 5 Total'})  # Rename for clarity\n",
    ")\n",
    "\n",
    "# Aggregate Top 5 totals across all ages as a feature for each player\n",
    "top_5_aggregated = (\n",
    "    top_5_totals.groupby('Player ID')['Top 5 Total']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Top 5 Total': 'Top 5 Aggregated'})\n",
    ")\n",
    "\n",
    "# Merge aggregated \"Top 5\" totals back into the main DataFrame\n",
    "players_df = players_df.merge(top_5_aggregated, on='Player ID', how='left')\n",
    "baseline_players = baseline_players.merge(top_5_aggregated, on='Player ID', how='left')\n",
    "\n",
    "# Update the list of features to include encoded columns and 'Top 5 Aggregated'\n",
    "encoded_features = encoded_df.columns.tolist()\n",
    "all_features = features + encoded_features + ['Top 5 Aggregated']\n",
    "\n",
    "# Aggregate cumulative stats for each player by summing all rows\n",
    "players_aggregated = players_df.groupby(['Player ID', 'Name'])[all_features].sum().reset_index()\n",
    "baseline_aggregated = baseline_players.groupby(['Player ID', 'Name'])[all_features].sum().reset_index()\n",
    "\n",
    "# Check if data for comparison exists\n",
    "if players_aggregated.empty or baseline_aggregated.empty:\n",
    "    print(\"No players or baseline players left after filtering. Exiting...\")\n",
    "else:\n",
    "    # Step 1: Scale features for similarity calculation\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(baseline_aggregated[all_features])\n",
    "\n",
    "    # Apply scaling to player stats\n",
    "    players_scaled = scaler.transform(players_aggregated[all_features])\n",
    "    baseline_scaled = scaler.transform(baseline_aggregated[all_features])\n",
    "\n",
    "    # Step 2: Compute similarity between each player and baseline players\n",
    "    similar_results_all = []\n",
    "    for idx, player in players_aggregated.iterrows():\n",
    "        player_id, player_name = player['Player ID'], player['Name']  # Extract player info\n",
    "\n",
    "        # Scale the player's features\n",
    "        player_scaled = players_scaled[idx].reshape(1, -1)\n",
    "\n",
    "        # Calculate cosine similarity with baseline players\n",
    "        similarities = cosine_similarity(player_scaled, baseline_scaled).flatten()\n",
    "\n",
    "        # Combine similarity scores with baseline player details\n",
    "        baseline_aggregated_copy = baseline_aggregated.copy()\n",
    "        baseline_aggregated_copy['Similarity'] = similarities\n",
    "\n",
    "        # Exclude the player itself from the similarity results\n",
    "        baseline_aggregated_copy = baseline_aggregated_copy[baseline_aggregated_copy['Player ID'] != player_id]\n",
    "\n",
    "        # Identify the top 3 most similar players\n",
    "        top_3 = (\n",
    "            baseline_aggregated_copy.sort_values(by='Similarity', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        # Record the similarity results\n",
    "        similar_results_all.append({\n",
    "            'Player ID': player_id,\n",
    "            'Player Name': player_name,\n",
    "            'First Similar Player': top_3.iloc[0]['Name'] if len(top_3) > 0 else None,\n",
    "            'Similarity Score 1': top_3.iloc[0]['Similarity'] if len(top_3) > 0 else None,\n",
    "            'Second Similar Player': top_3.iloc[1]['Name'] if len(top_3) > 1 else None,\n",
    "            'Similarity Score 2': top_3.iloc[1]['Similarity'] if len(top_3) > 1 else None,\n",
    "            'Third Similar Player': top_3.iloc[2]['Name'] if len(top_3) > 2 else None,\n",
    "            'Similarity Score 3': top_3.iloc[2]['Similarity'] if len(top_3) > 2 else None\n",
    "        })\n",
    "\n",
    "    # Step 3: Save the similarity results\n",
    "    all_results_df = pd.DataFrame(similar_results_all)\n",
    "    output_file_all = '../data/cleaned/all_similar_players.csv'  # Path for saving results\n",
    "    all_results_df.to_csv(output_file_all, index=False)\n",
    "\n",
    "    # Confirm saving the results\n",
    "    print(f\"All results saved to {output_file_all}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
